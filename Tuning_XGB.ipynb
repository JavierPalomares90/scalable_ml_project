{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.utils as utils\n",
    "import models.xgboost_model as xgb_model\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pitch_data():\n",
    "    # Read csv files of saved pitch data from the MLB 2016-2019 seasons\n",
    "    pitch_data = pd.read_csv('raw_pitch_data_all_base_v2.csv', index_col=0)\n",
    "    print(\"pitch data loaded\")\n",
    "    return pitch_data\n",
    "\n",
    "def filter_pitch_data(pitch_data):\n",
    "    pre_filter_rows = len(pitch_data.index)\n",
    "    pitch_data = pitch_data[pd.notnull(pitch_data['p1_pitch_type'])]\n",
    "    post_filter_rows = len(pitch_data.index)\n",
    "\n",
    "    filter_diff = pre_filter_rows - post_filter_rows\n",
    "    filter_pcnt = (filter_diff)/pre_filter_rows\n",
    "\n",
    "    print('Removed Null/NaN labeled pitch types rows, filtered %d of %d rows at %f%%' % (filter_diff, pre_filter_rows, filter_pcnt))\n",
    "    return pitch_data\n",
    "\n",
    "def drop_pitch_types(pitch_data):\n",
    "    #\n",
    "    # Drop rows with unwanted pitchtypes (including automatic ball/strikes, pitchouts, etc)\n",
    "    #\n",
    "    pre_filter_rows = len(pitch_data.index)\n",
    "    pitch_data = utils.drop_unwanted_pitches(pitch_data)\n",
    "    post_filter_rows = len(pitch_data.index)\n",
    "\n",
    "    filter_diff = pre_filter_rows - post_filter_rows\n",
    "    filter_pcnt = (filter_diff)/pre_filter_rows\n",
    "\n",
    "    print('Removed rows w/ unwanted pitch types, filtered %d of %d rows at %f%%' % (filter_diff, pre_filter_rows, filter_pcnt))\n",
    "    return pitch_data\n",
    "\n",
    "def drop_columns(pitch_data):\n",
    "    #\n",
    "    # Drop unwanted dataset columns \n",
    "    # \n",
    "\n",
    "    # ID columns to drop\n",
    "    id_cols_to_drop=['p1_pitch_id','p0_pitch_id','pitch_data_id','team_id','game_id',\n",
    "                    'inning_id','half_inning_id','at_bat_id','gid','b1_id','b1_team_id',\n",
    "                    'team_abbrev']\n",
    "    pitch_data = utils.drop_columns_by_list(pitch_data,id_cols_to_drop)\n",
    "    # Pitch data columns to drop\n",
    "    pitch_cols_to_drop = ['p0_pitch_seqno', 'p1_pitch_seqno', 'p0_inning', 'result_type',\n",
    "                          'type_confidence', 'p0_at_bat_o', 'p0_pitch_des', 'nasty']\n",
    "    pitch_data = utils.drop_columns_by_list(pitch_data, pitch_cols_to_drop)\n",
    "\n",
    "    # Optional pitchf/x data columns to drop\n",
    "    #pitchfx_cols_to_drop = ['pitch_count_atbat', 'pitch_count_team', 'start_speed', 'spin_dir',\n",
    "    #                        'x', 'y', 'sz_top', 'sz_bot', 'pfx_x', 'pfx_z', 'px', 'pz',\n",
    "    #                        'x0', 'y0', 'z0', 'vx0', 'vy0', 'vz0', 'ax', 'ay', 'az', 'break_y']\n",
    "    #pitch_data = utils.drop_columns_by_list(pitch_data, pitchfx_cols_to_drop)\n",
    "\n",
    "    print(\"dropped cols\")\n",
    "    return pitch_data\n",
    "\n",
    "def add_run_diff(pitch_data):\n",
    "    #\n",
    "    # Create new column of run differential\n",
    "    #\n",
    "    pitch_data['run_diff'] = pitch_data['runs_pitcher_team'] - pitch_data['runs_batter_team']\n",
    "    cols_to_drop=['runs_pitcher_team','runs_batter_team']\n",
    "    pitch_data = utils.drop_columns_by_list(pitch_data, cols_to_drop)\n",
    "    print(\"added run diff\")\n",
    "    return pitch_data\n",
    "\n",
    "def add_crunch_time(pitch_data):\n",
    "    #\n",
    "    # Create new column for crunch time (after 7th inning)\n",
    "    #\n",
    "    pitch_data['inning'] = pitch_data['inning'].astype(dtype='int64')\n",
    "    pitch_data['inning'] = pitch_data['inning'].fillna(0)  # '0' is for unknown inning (Other values are 1-9)\n",
    "    pitch_data['crunch_time'] = np.where(pitch_data['inning'] > 7, 1, 0)\n",
    "    cols_to_drop=['inning']\n",
    "    pitch_data = utils.drop_columns_by_list(pitch_data, cols_to_drop)\n",
    "    print(\"added crunch time\")\n",
    "    return pitch_data\n",
    "\n",
    "def replace_nans(pitch_data):\n",
    "    #\n",
    "    # Replace Nulls/NaN values that are left in the remaining object columns\n",
    "    #\n",
    "    #\n",
    "    # Replace Nulls/NaN values that are left in the remaining object columns\n",
    "    #\n",
    "    pitch_data['p0_pitch_type'] = pitch_data['p0_pitch_type'].fillna('NP')  # 'NP' is for No Pitch\n",
    "\n",
    "    pitch_data['result_type_simple'] = pitch_data['result_type_simple'].fillna('X')  # 'X' is for in play\n",
    "\n",
    "    pitch_data['b1_game_position'] = pitch_data['b1_game_position'].fillna('Unknown')\n",
    "\n",
    "    pitch_data['b1_bats'] = pitch_data['b1_bats'].fillna('R')  # 'R' is for right handed (Other values are L or S)\n",
    "\n",
    "    pitch_data['throws'] = pitch_data['throws'].fillna('R')  # 'R' is for right handed (Other value is L)\n",
    "\n",
    "    #pitch_data['inning'] = pitch_data['inning'].fillna('0')  # '0' is for unknown inning (Other values are 1-9)\n",
    "\n",
    "    print('Current number of dataframe Null/NaN values: %d' % (pitch_data.isnull().sum().sum()))\n",
    "    #\n",
    "    # Fill the rest of Null/NaN values with zero in numeric columns\n",
    "    #\n",
    "    replace_dict = {'nasty': 0, 'x': 0, 'y': 0, 'sz_top': 0, 'sz_bot': 0, 'pfx_x': 0, 'pfx_z': 0,\n",
    "                    'px': 0, 'pz': 0, 'x0': 0, 'y0': 0, 'z0': 0, 'vx0': 0, 'vy0': 0, 'vz0': 0,\n",
    "                    'ax': 0, 'ay': 0, 'az': 0, 'break_y': 0, 'break_angle': 0, 'break_length': 0,\n",
    "                    'start_speed': 0, 'end_speed': 0, 'zone': 0, 'outcome': 0, 'spin_rate': 0,\n",
    "                    'spin_dir': 0, 'pitch_count_at_bat': 0, 'pitch_count_team': 0,\n",
    "                    'wins': 0, 'losses': 0, 'b1_bat_order': 0}\n",
    "    pitch_data = pitch_data.fillna(value=replace_dict)\n",
    "\n",
    "    print('Current number of dataframe Null/NaN values: %d' % (pitch_data.isnull().sum().sum()))\n",
    "\n",
    "    return pitch_data\n",
    "\n",
    "def encode_object_data(pitch_data):\n",
    "    print('Encoding pitch dataframe of shape {}...'.format(pitch_data.shape))\n",
    "\n",
    "    # Split label column from rest of pitch dataframe then encode\n",
    "    Y_all = pitch_data.loc[:, 'p1_pitch_type'].copy()\n",
    "    Y_all = utils.encode_simple_pitch_types(Y_all)\n",
    "\n",
    "    # Drop label colum from pitch dataframe, then one-hot-encode object columns\n",
    "    pitch_data = pitch_data.drop('p1_pitch_type', axis=1)\n",
    "    pitch_data = utils.one_hot_encode(pitch_data,False)\n",
    "\n",
    "    # Insert label data back into pitch dataframe\n",
    "    pitch_data['p1_pitch_type'] = Y_all.copy()\n",
    "\n",
    "    print('Pitch dataframe encoding complete. New shape: {}'.format(pitch_data.shape))\n",
    "    return pitch_data\n",
    "\n",
    "def split_train_test(pitch_data):\n",
    "    pd_train = pitch_data[pitch_data['season']!=2019].copy()\n",
    "    pd_test = pitch_data[pitch_data['season']==2019].copy()\n",
    "\n",
    "    print('Shape of ALL training data set is {}'.format(pd_train.shape))\n",
    "    print('Shape of ALL test data set is {}'.format(pd_test.shape))\n",
    "\n",
    "    return pd_train,pd_test\n",
    "\n",
    "def get_pitcher_data(pd_train,pd_test,pitcher_id):\n",
    "    pd_train_pitcher = pd_train[pd_train['pitcher_id']==pitcher_id].copy()\n",
    "    pd_test_pitcher = pd_test[pd_test['pitcher_id']==pitcher_id].copy()\n",
    "    return pd_train_pitcher,pd_test_pitcher\n",
    "\n",
    "\n",
    "def drop_season_pitch_id_cols(pd_train,pd_test):\n",
    "    cols_to_drop=['season','pitcher_id']\n",
    "    pd_test = utils.drop_columns_by_list(pd_test, cols_to_drop)\n",
    "    pd_train = utils.drop_columns_by_list(pd_train, cols_to_drop)\n",
    "    return pd_train,pd_test\n",
    "\n",
    "def get_X_Y(pitch_data,num_pitch_types):\n",
    "    X = pitch_data.drop('p1_pitch_type',axis=1).copy()\n",
    "    Y = pitch_data.loc[:,'p1_pitch_type'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Get the data and do all necessary feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 75 fields in line 2315258, saw 76\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7fdce4103825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpitch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pitch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpitch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_pitch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpitch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_pitch_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpitch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpitch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madd_run_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpitch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8dfb03a9884e>\u001b[0m in \u001b[0;36mget_pitch_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_pitch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Read csv files of saved pitch data from the MLB 2016-2019 seasons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpitch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'raw_pitch_data_all_base_v2.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pitch data loaded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpitch_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 75 fields in line 2315258, saw 76\n"
     ]
    }
   ],
   "source": [
    "pitch_data = get_pitch_data()\n",
    "pitch_data = filter_pitch_data(pitch_data)\n",
    "pitch_data = drop_pitch_types(pitch_data)\n",
    "pitch_data = drop_columns(pitch_data)\n",
    "pitch_data = add_run_diff(pitch_data)\n",
    "pitch_data = add_crunch_time(pitch_data)\n",
    "# Set intended data types of the remaining columns\n",
    "pitch_data = utils.set_dtypes(pitch_data)\n",
    "pitch_data['season'] = pitch_data['season'].astype(dtype='int64')\n",
    "pitch_data['pitcher_id'] = pitch_data['pitcher_id'].astype(dtype='int64')\n",
    "pitch_data = replace_nans(pitch_data)\n",
    "pitch_data = encode_object_data(pitch_data)\n",
    "pd_train,pd_test = split_train_test(pitch_data)\n",
    "# get the data for top 3 pitchers\n",
    "pd_train_verlander,pd_test_verlander = get_pitcher_data(pd_train,pd_test,434378)\n",
    "pd_train_scherzer,pd_test_scherzer= get_pitcher_data(pd_train,pd_test,453286)\n",
    "pd_train_porcello,pd_test_porcello= get_pitcher_data(pd_train,pd_test,519144)\n",
    "print('Verlander pitch data rows: train=%d, test=%d.' % (len(pd_train_verlander.index), len(pd_test_verlander.index)))\n",
    "print('Scherzer pitch data rows: train=%d, test=%d.' % (len(pd_train_scherzer.index), len(pd_test_scherzer.index)))\n",
    "print('Porcello pitch data rows: train=%d, test=%d.' % (len(pd_train_porcello.index), len(pd_test_porcello.index)))\n",
    "\n",
    "# Lastly drop season and pitch_id columns\n",
    "pd_train,pd_test = drop_season_pitch_id_cols(pd_train,pd_test)\n",
    "pd_train_verlander,pd_test_verlander = drop_season_pitch_id_cols(pd_train_verlander,pd_test_verlander)\n",
    "pd_train_scherzer,pd_test_scherzer = drop_season_pitch_id_cols(pd_train_scherzer,pd_test_scherzer)\n",
    "pd_train_porcello,pd_test_porcello = drop_season_pitch_id_cols(pd_train_porcello,pd_test_porcello)\n",
    "\n",
    "num_pitch_types = 16\n",
    "# get the NN data for Verlander\n",
    "X_test_verlander,Y_test_verlander = get_X_Y(pd_test_verlander,num_pitch_types)\n",
    "X_train_verlander,Y_train_verlander = get_X_Y(pd_train_verlander,num_pitch_types)\n",
    "num_cols = len(X_test_verlander.iloc[0,:])\n",
    "\n",
    "# train the model for verlander\n",
    "model_verlander = xgb_model.get_multi_class_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
